{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import Image\n",
    "import math\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  These data were created by 610 users between March 29, 1996 and September 24, 2018. This dataset was generated on September 26, 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df =  pd.read_csv(\"../data/ml-latest-small/ratings.csv\")\n",
    "\n",
    "df['time'] = df['timestamp'].apply(datetime.fromtimestamp)\n",
    "df_time = df.sort_values('time', ascending = True)\n",
    "df_time['time'] = pd.to_datetime(df_time.time).dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9724"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_time['movieId'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bin the dataset based on years:1996-2003, 2004-2011, 2012-2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8, 8, 7 years\n",
    "# split into bins\n",
    "bin1 = df_time[df_time['time'] <= '2003-12-31']\n",
    "bin2 = df_time[(df_time['time'] <= '2011-12-31') & (df_time['time'] > '2003-12-31')]\n",
    "bin3 = df_time[(df_time['time'] > '2011-12-31' )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin1_train, bin1_test, r1_train, r1_test = train_test_split(bin1[['userId', 'movieId','time']], bin1['rating'], test_size=0.2, random_state=42)\n",
    "bin2_train, bin2_test, r2_train, r2_test = train_test_split(bin2[['userId', 'movieId','time']], bin2['rating'], test_size=0.2, random_state=42)\n",
    "bin3_train, bin3_test, r3_train, r3_test = train_test_split(bin3[['userId', 'movieId','time']], bin3['rating'], test_size=0.2, random_state=42)\n",
    "\n",
    "bin1_train['rating'] = r1_train\n",
    "bin2_train['rating'] = r2_train\n",
    "bin3_train['rating'] = r3_train\n",
    "\n",
    "bin1_test['rating'] = r1_test\n",
    "bin2_test['rating'] = r2_test\n",
    "bin3_test['rating'] = r3_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to remove unseen movieId and userId and add them back to train dataset\n",
    "def move_unseen(train, test):\n",
    "    move1 = test[~test.movieId.isin(train.movieId)]\n",
    "    test = test[test.movieId.isin(train.movieId)]\n",
    "    \n",
    "    move2 = test[~test.userId.isin(train.userId)]\n",
    "    test = test[test.userId.isin(train.userId)]\n",
    "    \n",
    "    train = pd.concat([train, move1, move2])\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin1_train, bin1_test = move_unseen(bin1_train, bin1_test)\n",
    "bin2_train, bin2_test = move_unseen(bin2_train, bin2_test)\n",
    "bin3_train, bin3_test = move_unseen(bin3_train, bin3_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8212304589006556"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin3_train.shape[0]/(bin3_train.shape[0] + bin3_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to user-movie matrix\n",
    "R1_train = bin1_train.pivot_table(index='userId', columns='movieId', values='rating')\n",
    "R1_test = bin1_test.pivot_table(index='userId', columns='movieId', values='rating')\n",
    "\n",
    "R2_train = bin2_train.pivot_table(index='userId', columns='movieId', values='rating')\n",
    "R2_test = bin2_test.pivot_table(index='userId', columns='movieId', values='rating')\n",
    "\n",
    "R3_train = bin3_train.pivot_table(index='userId', columns='movieId', values='rating')\n",
    "R3_test = bin3_test.pivot_table(index='userId', columns='movieId', values='rating')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_train = pd.concat([bin1_train, bin2_train, bin3_train])\n",
    "R = all_train.pivot_table(index='userId', columns='movieId', values='rating') # all train item-user matrix\n",
    "\n",
    "mu = all_train['rating'].mean()\n",
    "### bu\n",
    "bu = pd.DataFrame(np.nanmean(R, axis=1) - mu)  #bias for users among all train\n",
    "bu['userId'] = R.index\n",
    "\n",
    "bu1 = bu[bu['userId'].isin(R1_train.index)]\n",
    "bu2 = bu[bu['userId'].isin(R2_train.index)]\n",
    "bu3 = bu[bu['userId'].isin(R3_train.index)]\n",
    "\n",
    "### bi\n",
    "bi = pd.DataFrame(np.nanmean(R, axis=0) - mu) #bias for movies among all train\n",
    "bi['movieId'] = R.columns\n",
    "\n",
    "bi1 = bi[bi['movieId'].isin(R1_train.columns)]\n",
    "bi2 = bi[bi['movieId'].isin(R2_train.columns)]\n",
    "bi3 = bi[bi['movieId'].isin(R3_train.columns)]\n",
    "\n",
    "# calculate bi,bin(t)\n",
    "mu1 = bin1_train['rating'].mean()\n",
    "bit1 = pd.DataFrame(np.nanmean(R1_train, axis = 0) - mu1)\n",
    "bi1 = pd.DataFrame(bi1.reset_index(drop= True)[0]+bit1[0])\n",
    "bi1['movieId'] = R1_train.columns\n",
    "\n",
    "mu2 = bin2_train['rating'].mean()\n",
    "bit2 = pd.DataFrame(np.nanmean(R2_train, axis = 0) - mu2)\n",
    "bi2 = pd.DataFrame(bi2.reset_index(drop= True)[0]+bit2[0])\n",
    "bi2['movieId'] = R2_train.columns\n",
    "\n",
    "mu3 = bin3_train['rating'].mean()\n",
    "bit3 = pd.DataFrame(np.nanmean(R3_train, axis = 0) - mu3)\n",
    "bi3 = pd.DataFrame(bi3.reset_index(drop= True)[0]+bit3[0])\n",
    "bi3['movieId'] = R3_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### what we have in the end:\n",
    "- train datasets: bin1_train,  bin2_train,  bin3_train\n",
    "- test datasets: bin1_test, bin2_test, bin3_test\n",
    "\n",
    "- train rating matrix: R1_train, R2_train, R3_train\n",
    "\n",
    "- temporal dynamics bias: bu1, bu2, bu3, bi1, bi2, bi3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
